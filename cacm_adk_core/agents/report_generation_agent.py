import logging
import json 
from typing import Dict, Any, Optional

from cacm_adk_core.agents.base_agent import Agent
from cacm_adk_core.semantic_kernel_adapter import KernelService # For consistency, though not directly used by this agent's current logic
from cacm_adk_core.context.shared_context import SharedContext


class ReportGenerationAgent(Agent):
    """
    Agent responsible for assembling a comprehensive report by consolidating 
    outputs from various analytical agents and relevant data from SharedContext.

    It primarily uses structured data passed via `current_step_inputs` (which are typically
    bound to the outputs of upstream agents like FundamentalAnalystAgent, SNCAnalystAgent, 
    and CatalystWrapperAgent) and textual data (like company overview and risk factors)
    retrieved directly from `SharedContext`.
    """
    def __init__(self, kernel_service: KernelService):
        super().__init__(agent_name="ReportGenerationAgent", kernel_service=kernel_service)

    async def run(self, task_description: str, current_step_inputs: Dict[str, Any], shared_context: SharedContext) -> Dict[str, Any]:
        self.logger.info(f"'{self.agent_name}' received task: {task_description} with inputs: {current_step_inputs}")
        self.logger.info(f"Operating with SharedContext ID: {shared_context.get_session_id()} (CACM ID: {shared_context.get_cacm_id()})")

        fundamental_analysis_input = current_step_inputs.get("fundamental_analysis_data_ref")
        snc_analysis_input = current_step_inputs.get("snc_analysis_data_ref")
        catalyst_input = current_step_inputs.get("catalyst_data_ref")

        company_name = shared_context.get_data("company_name", "N/A")
        company_ticker = shared_context.get_data("company_ticker", "N/A")
        business_overview_text = shared_context.get_data("structured_financials_for_summary", "[Business Overview Not Available]")
        risk_factors_text = shared_context.get_data("risk_factors_section_text", "[Risk Factors Text Not Available]")
        
        self.logger.info(f"Retrieved data for report generation. Company: {company_name}")

        report_parts = []
        report_title_detail = current_step_inputs.get("report_title_detail", "Comprehensive Analysis Report")
        report_parts.append(f"# {report_title_detail} for {company_name} ({company_ticker})")
        report_parts.append(f"## Task: {task_description}")
        report_parts.append(f"Generated by: {self.agent_name} for CACM ID: {shared_context.get_cacm_id()} (Session: {shared_context.get_session_id()})")
        report_parts.append("---")

        # Initialize placeholders for LLM summaries
        llm_financial_summary = None
        llm_risk_summary = None
        llm_overall_assessment = None

        # Check stored_results for LLM summaries from AnalysisAgent (or similar)
        if hasattr(self, 'stored_results') and self.stored_results:
            for res_item in self.stored_results:
                # Assuming AnalysisAgent is the one providing these specific keys
                # A more robust check might be res_item.get('from') == 'AnalysisAgent'
                # and then checking the 'data' payload.
                data_payload = res_item.get('data', {})
                if 'financial_summary' in data_payload: # Key used by AnalysisAgent for its LLM output
                    llm_financial_summary = data_payload['financial_summary']
                    self.logger.info(f"Found LLM-generated financial summary from agent '{res_item.get('from', 'Unknown')}'.")
                if 'risk_summary' in data_payload: # Key used by AnalysisAgent
                    llm_risk_summary = data_payload['risk_summary']
                    self.logger.info(f"Found LLM-generated key risks summary from agent '{res_item.get('from', 'Unknown')}'.")
                if 'overall_assessment' in data_payload: # Key used by AnalysisAgent
                    llm_overall_assessment = data_payload['overall_assessment']
                    self.logger.info(f"Found LLM-generated overall assessment from agent '{res_item.get('from', 'Unknown')}'.")

        report_parts.append("## 1. Company Overview / Financial Performance")
        if llm_financial_summary:
            self.logger.info("Using LLM-generated financial summary for report section.")
            report_parts.append("### AI-Generated Financial Performance Summary:")
            report_parts.append(llm_financial_summary)
            if isinstance(business_overview_text, dict): # Still include original data if it's structured
                report_parts.append("\n### Original Company Overview Data (Structured):")
                report_parts.append(f"```json\n{json.dumps(business_overview_text, indent=2)}\n```")
            elif business_overview_text != llm_financial_summary : # Or if it's different text
                 report_parts.append("\n### Original Company Overview Text (from SharedContext):")
                 report_parts.append(str(business_overview_text))
        elif isinstance(business_overview_text, dict):
            self.logger.info("Using 'structured_financials_for_summary' (dict) from SharedContext for Company Overview.")
            report_parts.append(json.dumps(business_overview_text, indent=2))
        else:
            self.logger.info("Using 'structured_financials_for_summary' (text) from SharedContext for Company Overview.")
            report_parts.append(str(business_overview_text))
        
        report_parts.append("\n## 2. Fundamental Analysis")
        if fundamental_analysis_input and isinstance(fundamental_analysis_input, dict):
            # fundamental_analysis_input is the 'data' field from FundamentalAnalystAgent
            ratios = fundamental_analysis_input.get('financial_ratios')
            analysis_summary = fundamental_analysis_input.get('analysis_summary', "Fundamental analysis summary not available.")
            dcf_valuation = fundamental_analysis_input.get('dcf_valuation', 'N/A')
            enterprise_value = fundamental_analysis_input.get('enterprise_value', 'N/A')
            financial_health = fundamental_analysis_input.get('financial_health', 'N/A')

            # Retrieve LLM-generated explanations for ratios
            key_ratios_explanations_map = shared_context.get_data("key_ratios_explanations_llm", {})
            if key_ratios_explanations_map:
                self.logger.info("Retrieved LLM-generated explanations for key ratios from SharedContext.")
            else:
                self.logger.info("No LLM-generated explanations for key ratios found in SharedContext. Ratios will be reported without them.")

            report_parts.append("### Key Financial Ratios:")
            if ratios and isinstance(ratios, dict):
                for key, value in ratios.items():
                    # Append ratio name and value
                    report_parts.append(f"- **{key.replace('_', ' ').title()}:** {value:.2f}" if isinstance(value, (float, int)) else f"- **{key.replace('_', ' ').title()}:** {value}")
                    # Append explanation if available
                    explanation_text = key_ratios_explanations_map.get(key)
                    if explanation_text:
                        # Ensure explanation is not overly long or contains disruptive newlines for bullet point format
                        explanation_text_cleaned = explanation_text.replace('\n', ' ').strip()
                        report_parts.append(f"    - *Explanation:* {explanation_text_cleaned}")
            else:
                report_parts.append("- No financial ratios provided or found in expected structure.")
            
            report_parts.append(f"\n### DCF Valuation: {dcf_valuation if dcf_valuation not in ['N/A', None] and isinstance(dcf_valuation, (int, float)) else 'N/A'}")
            report_parts.append(f"### Enterprise Value: {enterprise_value if enterprise_value not in ['N/A', None] and isinstance(enterprise_value, (int, float)) else 'N/A'}")
            report_parts.append(f"### Financial Health Assessment: {financial_health}")
            report_parts.append("\n### Analysis Summary:")
            report_parts.append(analysis_summary)
        else:
            report_parts.append("Fundamental analysis data not available or not in expected format.")

        report_parts.append("\n## 3. Shared National Credit (SNC) Analysis")
        if snc_analysis_input and isinstance(snc_analysis_input, dict):
            # snc_analysis_input is the 'data' field from SNCAnalystAgent
            report_parts.append(f"**SNC Rating:** {snc_analysis_input.get('rating', '[Rating not provided]')}")
            report_parts.append("\n**Rationale:**")
            report_parts.append(snc_analysis_input.get('rationale', '[Rationale not provided]'))
        else:
            report_parts.append("SNC analysis data not available or not in expected format.")

        report_parts.append("\n## 4. Catalyst Strategic Insights")
        if catalyst_input and isinstance(catalyst_input, dict):
            # catalyst_input is the 'data' field from CatalystWrapperAgent
            report_parts.append("```json")
            report_parts.append(json.dumps(catalyst_input, indent=2))
            report_parts.append("```")
        else:
            report_parts.append("Catalyst strategic insights not available or not in expected format.")

        report_parts.append("\n## 5. Key Risk Factors")
        if llm_risk_summary:
            self.logger.info("Using LLM-generated key risks summary for report section.")
            report_parts.append("### AI-Generated Key Risks Summary:")
            report_parts.append(llm_risk_summary)
            if risk_factors_text != llm_risk_summary: # Optionally append original if different
                report_parts.append("\n### Original Risk Factors Text (from SharedContext):")
                report_parts.append(risk_factors_text)
        else:
            self.logger.info("Using 'risk_factors_section_text' from SharedContext for Key Risk Factors.")
            report_parts.append(risk_factors_text)

        # Add LLM Overall Assessment if available
        current_section_number = 5 # Last section was 5. Key Risk Factors
        if llm_overall_assessment:
            current_section_number += 1
            report_parts.append(f"\n## {current_section_number}. AI-Generated Overall Assessment")
            self.logger.info("Adding LLM-generated overall assessment to report.")
            report_parts.append(llm_overall_assessment)
        else:
            self.logger.info("LLM-generated overall assessment not found in stored results. Section will be omitted.")

        # Retrieve and add Summarized ESG Data
        summarized_esg_data = shared_context.get_data("summarized_esg_data")
        if summarized_esg_data and isinstance(summarized_esg_data, dict):
            current_section_number += 1
            report_parts.append(f"\n## {current_section_number}. ESG Factors Summary")
            self.logger.info("Adding ESG Factors Summary section to the report.")

            # Company name is already in the main report title, so not repeated here unless desired.
            # if summarized_esg_data.get("company_name"):
            #     report_parts.append(f"### For Company: {summarized_esg_data.get('company_name')}")

            for category_key, category_title in [
                ("overall_ratings", "Overall ESG Ratings"),
                ("environmental", "Environmental Factors"),
                ("social", "Social Factors"),
                ("governance", "Governance Factors")
            ]:
                category_data = summarized_esg_data.get(category_key)
                if category_data: # Check if list is not empty or key exists
                    report_parts.append(f"\n### {category_title}")
                    if isinstance(category_data, list) and category_data:
                        for item_index, item in enumerate(category_data):
                            # Ensure item is a string; ESGAnalysisSkill should format them already
                            report_parts.append(f"- {str(item)}") 
                    elif isinstance(category_data, list) and not category_data: # Empty list
                        report_parts.append(f"- No specific data points listed for {category_title}.")
                    elif isinstance(category_data, str): # Should ideally be a list from ESGAnalysisSkill
                         report_parts.append(category_data) # Append string directly if that's what it is
                    # else: report_parts.append(f"- Data for {category_title} is in an unexpected format.") # Optional
            
            other_metrics = summarized_esg_data.get("other_metrics")
            if other_metrics and isinstance(other_metrics, list) and other_metrics:
                report_parts.append("\n### Other Uncategorized Metrics")
                for item in other_metrics:
                    report_parts.append(f"- {str(item)}")

            processing_notes = summarized_esg_data.get("processing_notes")
            if processing_notes and isinstance(processing_notes, list) and processing_notes:
                report_parts.append("\n#### Processing Notes (from ESG Analysis):")
                for note in processing_notes:
                    report_parts.append(f"- *{str(note)}*")
        else:
            self.logger.info("Summarized ESG data not found in SharedContext or not in expected dict format. ESG section will be omitted.")
            # Optionally, add a placeholder section indicating data is missing:
            # current_section_number += 1
            # report_parts.append(f"\n## {current_section_number}. ESG Factors Summary")
            # report_parts.append("[Summarized ESG data not available.]")


        if current_step_inputs:
            current_section_number += 1
            report_parts.append(f"\n## {current_section_number}. Additional Report Parameters (Step Inputs)")
            filtered_inputs_for_display = {k: v for k, v in current_step_inputs.items() if not k.endswith("_data_ref") and k != "output_dir"}
            report_parts.append(f"```json\n{json.dumps(filtered_inputs_for_display, indent=2)}\n```")

        if hasattr(self, 'stored_results') and self.stored_results:
            current_section_number += 1
            report_parts.append(f"\n## {current_section_number}. Raw Data Received via Direct Agent Communication")
            for i, res_item in enumerate(self.stored_results):
                # Avoid re-printing the already processed LLM summaries if they were the sole content of a payload.
                # This is a simple check; a more robust way would be to mark items as "processed".
                data_payload = res_item.get('data', {})
                is_analysis_payload = 'financial_summary' in data_payload or \
                                      'risk_summary' in data_payload or \
                                      'overall_assessment' in data_payload
                
                # Heuristic: if it's an analysis payload AND all its main summary components were used,
                # it might be redundant to print the whole thing again if it ONLY contained those.
                # However, AnalysisAgent payload also contains 'analysis_status', 'ratios_payload' etc.
                # So, it's generally still useful to print.
                # For now, let's just add a note if it seems like an AnalysisAgent payload.
                agent_name_from_payload = res_item.get('from', 'Unknown')
                title_note = ""
                if is_analysis_payload and agent_name_from_payload == "AnalysisAgent": # Or check for specific agent name
                    title_note = " (Note: LLM summaries from this payload may have been integrated above)"

                report_parts.append(f"**Item {i+1} from Agent '{agent_name_from_payload}'{title_note}:**")
                report_parts.append(f"```json\n{json.dumps(data_payload, indent=2)}\n```")
        
        final_report_string = "\n\n".join(report_parts)
        self.logger.info(f"Report assembled. Length: {len(final_report_string)}")

        report_filename = f"generated_report_{shared_context.get_session_id()}_{shared_context.get_cacm_id()}.md"
        user_output_dir = current_step_inputs.get("output_dir")

        if user_output_dir:
            final_output_path = f"{user_output_dir}/{report_filename}"
        else:
            final_output_path = f"./output_artifacts/final_machine_reports/{report_filename}"

        self.logger.info(f"ReportGenerationAgent: Conceptual report file path determined as: {final_output_path}")
        self.logger.debug(f"Report Content for {report_filename}:\n{final_report_string}")
            
        report_package_output = {
            "content": final_report_string,
            "file_path": final_output_path,
            "status_message": "Report generated successfully."
        }

        return {
            "status": "success",
            "agent": self.agent_name,
            "message": "Report generated successfully and conceptually saved to file.",
            "report_package": report_package_output
        }

    async def receive_analysis_results(self, sending_agent_name: str, results: Dict[str, Any]):
        self.logger.info(f"'{self.agent_name}' received analysis results from '{sending_agent_name}'. Storing under 'stored_results'.")
        if not hasattr(self, 'stored_results'):
            self.stored_results = []
        self.stored_results.append({ "from": sending_agent_name, "data": results})
        self.logger.info(f"Results from '{sending_agent_name}' stored. Total stored items: {len(self.stored_results)}")

if __name__ == '__main__':
    logging.basicConfig(level=logging.INFO)
    class MockKernelService(KernelService):
        def __init__(self): self.logger = logging.getLogger("MockReportGenKernelService")
        def get_kernel(self): return None
        def _initialize_kernel(self): pass

    mock_service = MockKernelService()
    report_agent = ReportGenerationAgent(kernel_service=mock_service)
    test_shared_context = SharedContext(cacm_id="report_gen_test_001")

    test_shared_context.set_data("company_name", "TestCorp")
    test_shared_context.set_data("company_ticker", "TCORP")
    test_shared_context.set_data("calculated_key_ratios", {
        "current_ratio": 2.15, 
        "debt_to_equity_ratio": 0.65,
    })
    test_shared_context.set_data("financial_performance_summary_text", "[Placeholder Financial Summary - Test Data]")
    test_shared_context.set_data("key_risks_summary_text", "[Placeholder Risk Summary - Test Data]")
    test_shared_context.set_data("overall_assessment_text", "[Placeholder Overall Assessment - Test Data]")

    import asyncio
    async def test_run():
        await report_agent.receive_analysis_results(
            "MockAnalysisAgent", 
            {"summary": "Mock analysis summary", "key_metric": 123.45}
        )
        
        result = await report_agent.run(
            task_description="Generate the standard financial report.",
            current_step_inputs={
                "report_title_detail": "Annual Test Report",
                "fundamental_analysis_data_ref": { # Simulating orchestrator wrapping with "value"
                    "value": { # This is the actual "data" dict from FundamentalAnalystAgent
                        "company_id": "TEST",
                        "financial_ratios": {"current_ratio": 2.0, "debt_to_equity": 0.5},
                        "analysis_summary": "This is a test summary from FAA.",
                        "dcf_valuation": 100.50,
                        "enterprise_value": 120.75,
                        "financial_health": "Good"
                    }
                },
                "snc_analysis_data_ref": {
                    "value": { # This is the actual "data" dict from SNCAnalystAgent
                        "rating": "Pass",
                        "rationale": "Solid financials."
                    }
                },
                "catalyst_data_ref": {
                    "value": { # This is the actual "data" dict from CatalystWrapperAgent
                        "opportunity_id": "Opp123",
                        "details": "Strategic partnership potential."
                    }
                },
                "output_dir": "output_artifacts/test_report_gen"
            },
            shared_context=test_shared_context
        )
        print("\n--- Generated Report Text ---")
        # Access content from report_package
        report_package = result.get("report_package", {})
        print(report_package.get("content"))
        print(f"\nConceptual file path: {report_package.get('file_path')}")
        print(f"Agent status: {result.get('status')}, message: {result.get('message')}")
        
        print("\n--- SharedContext after Report Generation ---")
        test_shared_context.log_context_summary()

    asyncio.run(test_run())
