#!/usr/bin/env python3
"""
Ingest Expertise Definitions into Data Mesh Ontology Framework.

Purpose:
This script is responsible for parsing JSON definition files and populating a
"live" in-memory instance of the data mesh ontology framework. These JSON files
are typically generated by the `interactive_expertise_builder.py` script and
contain structured definitions for DataArtifacts, MLModels, and Federated Learning
setups. This script effectively bridges the gap between user-defined expertise
requirements and their representation as instantiated objects within the framework.

How to Run:
The script is executed from the command line. There are two main ways to specify input files:

1.  Using a common `expertise_id` (if files were generated by `interactive_expertise_builder.py`
    with its default naming convention):
    `python ingest_expertise_definitions.py --expertise_id <unique_expertise_id>`
    This will attempt to load:
    - `<unique_expertise_id>_data_artifacts.json`
    - `<unique_expertise_id>_ml_model.json`
    - `<unique_expertise_id>_federated_setup.json`

2.  Specifying individual file paths:
    `python ingest_expertise_definitions.py --artifacts_file /path/to/artifacts.json --model_file /path/to/model.json --fl_setup_file /path/to/fl_setup.json`
    You can provide one or more file types.

    Use `python ingest_expertise_definitions.py -h` for detailed command-line help. If no arguments
    are provided, the help message will be displayed.

Input:
- JSON files containing definitions for:
    - DataArtifacts (a list of artifact objects)
    - MLModels (a single model object)
    - FederatedLearningSetups (a single setup object)
  The structure of these JSON objects is expected to mirror the attributes of the
  corresponding classes in `framework.py`.

Output:
- The script modifies in-memory instances of the framework components (e.g., KnowledgeStore,
  MachineLearningGuidance, FederatedLearningInfra) by registering new objects based on
  the input JSON definitions.
- It produces console logs detailing the ingestion process, including successes, warnings,
  and errors.
- An activity log file (e.g., `ingestion_framework_activity.log`) is also generated by the
  `FrameworkLogger` instance.

Key Dependencies:
- `framework.py`: This script relies heavily on the class definitions (DataArtifact, MLModel, etc.)
  and component instances (KnowledgeStore, MachineLearningGuidance) from `framework.py`.
  It assumes `framework.py` is in the same directory or accessible via PYTHONPATH.
- Standard Python libraries: `json`, `argparse`, `os`, `logging`, `datetime`.

Typical Workflow & Testing:
1.  A user runs `interactive_expertise_builder.py` to answer questions about an
    expertise area. For example, using the default prompts might generate files based on
    an `expertise_id` (e.g., a UUID generated by the builder script). Let's assume
    this ID is `sample_expertise_123`. This step creates:
    - `sample_expertise_123_data_artifacts.json`
    - `sample_expertise_123_ml_model.json`
    - `sample_expertise_123_federated_setup.json`
2.  The user then runs this script (`ingest_expertise_definitions.py`), pointing it to
    the generated JSON files. For example:
    `python ingest_expertise_definitions.py --expertise_id sample_expertise_123`
    Alternatively, to test with specific files:
    `python ingest_expertise_definitions.py --artifacts_file sample_expertise_123_data_artifacts.json`
3.  This script parses the JSON files and instantiates corresponding objects from
    `framework.py` (e.g., `DataArtifact`, `MLModel`).
4.  These newly created objects are then registered with the appropriate framework
    components (e.g., DataArtifacts into KnowledgeStore, MLModels into MachineLearningGuidance).
5.  After successful execution, the in-memory instances of the framework components
    (KnowledgeStore, etc.) are populated with the new expertise definitions.
6.  (Future/External Step) Other tools, agents, or applications can then query and
    utilize these populated framework instances to act upon the defined expertise.
    (Note: This script currently only populates in-memory instances; persistence of
    these instances would be a separate concern managed by `framework.py` or another utility).
"""

import json
import argparse
import os
import logging
from datetime import datetime, timezone # Ensure timezone for consistency

# Setup basic Python logging for the script's own messages
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(script_level_log)s - %(levelname)s - %(message)s')

# Imports from the data mesh ontology framework (framework.py)
from framework import (
    KnowledgeStore,
    DataArtifact,
    MLModel,
    MachineLearningGuidance,
    FederatedLearningInfra,
    FederatedLearningNode,
    OntologyElement,
    FrameworkLogger,
    VersionControl
)

# --- Global Framework Component Instances ---
framework_logger: Optional[FrameworkLogger] = None
version_control: Optional[VersionControl] = None
knowledge_store: Optional[KnowledgeStore] = None
ml_guidance: Optional[MachineLearningGuidance] = None
federated_infra: Optional[FederatedLearningInfra] = None


def initialize_framework_components():
    """Initializes the core framework components for ingestion."""
    global framework_logger, version_control, knowledge_store, ml_guidance, federated_infra

    framework_logger = FrameworkLogger(log_file="ingestion_framework_activity.log")
    version_control = VersionControl(logger=framework_logger)
    knowledge_store = KnowledgeStore(logger_instance=framework_logger, version_control_instance=version_control)
    ml_guidance = MachineLearningGuidance(knowledge_store=knowledge_store, logger=framework_logger, version_control=version_control)

    federated_infra_id = str(uuid.uuid4())
    federated_infra = FederatedLearningInfra(
        id=federated_infra_id,
        name="DefaultIngestedFLInfrastructure",
        description="FL infrastructure instance configured by ingested definitions.",
        ml_guidance=ml_guidance,
        logger=framework_logger,
        version_control=version_control
    )
    knowledge_store.add_element(federated_infra)

    logging.info("Core framework components initialized for ingestion.")


def ingest_data_artifacts(file_path: str):
    """Loads DataArtifact definitions from a JSON file and registers them."""
    if not knowledge_store:
        logging.error("KnowledgeStore not initialized. Cannot ingest DataArtifacts.")
        return
    try:
        with open(file_path, 'r') as f: artifacts_data_list = json.load(f)
        if not isinstance(artifacts_data_list, list):
            logging.error(f"Invalid format in {file_path}. Expected a list."); return
        ingested_count = 0
        for artifact_data in artifacts_data_list:
            try:
                if 'id' not in artifact_data:
                    logging.warning(f"DataArtifact data missing 'id': {artifact_data.get('name', 'Unknown')}")
                artifact_instance = DataArtifact(**artifact_data)
                knowledge_store.register_artifact(artifact_instance)
                ingested_count += 1
                logging.info(f"DataArtifact '{artifact_instance.name}' (ID: {artifact_instance.id}) submitted for registration.")
            except Exception as e:
                logging.error(f"Failed to create/register DataArtifact (name: {artifact_data.get('name', 'Unknown')}): {e}", exc_info=True)
        logging.info(f"Attempted ingestion of {ingested_count}/{len(artifacts_data_list)} DataArtifacts from {file_path}.")
    except Exception as e:
        logging.error(f"Error during DataArtifact ingestion from {file_path}: {e}", exc_info=True)


def ingest_ml_model(file_path: str):
    """Loads an MLModel definition from a JSON file and registers it."""
    if not ml_guidance:
        logging.error("MachineLearningGuidance not initialized. Cannot ingest MLModel.")
        return
    try:
        with open(file_path, 'r') as f: model_data = json.load(f)
        if not isinstance(model_data, dict):
            logging.error(f"Invalid format in {file_path}. Expected a single object."); return
        try:
            if 'id' not in model_data:
                 logging.warning(f"MLModel data missing 'id': {model_data.get('name', 'Unknown')}")
            model_instance = MLModel(**model_data)
            ml_guidance.register_model(model_instance)
            logging.info(f"MLModel '{model_instance.name}' (ID: {model_instance.id}) submitted for registration.")
        except Exception as e:
            logging.error(f"Failed to create/register MLModel (name: {model_data.get('name', 'Unknown')}): {e}", exc_info=True)
    except Exception as e:
        logging.error(f"Error during MLModel ingestion from {file_path}: {e}", exc_info=True)


def ingest_federated_setup(file_path: str):
    """Loads a Federated Learning setup definition and configures it."""
    global federated_infra
    if not federated_infra:
        logging.error("FederatedLearningInfra not initialized. Cannot ingest FL setup."); return
    if not ml_guidance:
        logging.error("MachineLearningGuidance not initialized. Cannot fully configure FL setup."); return
    try:
        with open(file_path, 'r') as f: fl_setup_data = json.load(f)
        if not isinstance(fl_setup_data, dict):
            logging.error(f"Invalid format in {file_path}. Expected a single object."); return
        fl_setup_name = fl_setup_data.get('name', 'Unnamed FL Setup')
        logging.info(f"Processing Federated Learning Setup: {fl_setup_name}")

        original_infra_id = federated_infra.id
        new_infra_id = fl_setup_data.get('id')
        if new_infra_id and federated_infra.id != new_infra_id:
            logging.warning(f"Updating global FL Infra ID from '{original_infra_id}' to '{new_infra_id}' based on input file.")
            if knowledge_store and original_infra_id in knowledge_store.elements:
                 del knowledge_store.elements[original_infra_id] # Remove old ID from KS if present
            federated_infra.id = new_infra_id

        federated_infra.name = fl_setup_data.get('name', federated_infra.name)
        federated_infra.description = fl_setup_data.get('metadata', {}).get('description', federated_infra.description)
        federated_infra.version = fl_setup_data.get('version', federated_infra.version)
        federated_infra.updated_at = datetime.now(timezone.utc)

        global_model_id = fl_setup_data.get('global_model_id')
        if global_model_id:
            if ml_guidance.get_model(global_model_id):
                federated_infra.current_global_model_id = global_model_id
            else:
                logging.error(f"Global Model ID '{global_model_id}' in FL setup '{fl_setup_name}' not found in MLGuidance.")
        else:
            logging.warning(f"No 'global_model_id' in FL setup file: {file_path}")
        federated_infra.aggregation_strategy = fl_setup_data.get('aggregation_strategy', federated_infra.aggregation_strategy)

        data_distribution_plan = fl_setup_data.get('data_distribution_plan_by_category', {})
        if data_distribution_plan:
            logging.info(f"FL Data Distribution Plan for '{federated_infra.name}': {json.dumps(data_distribution_plan, indent=2)}")

        if knowledge_store: knowledge_store.add_element(federated_infra) # Re-register to update
        logging.info(f"Federated Learning Setup '{federated_infra.name}' (ID: {federated_infra.id}) configured/updated.")
    except Exception as e:
        logging.error(f"Error during FL setup ingestion from {file_path}: {e}", exc_info=True)


def main():
    """
    Main function to parse command-line arguments and orchestrate the ingestion process.
    It populates in-memory framework components based on JSON definitions.

    Testing Workflow:
    1. Generate definition files using `interactive_expertise_builder.py`.
       For example, if the builder outputs files based on an ID like 'test_exp_001',
       you'll get 'test_exp_001_data_artifacts.json', etc.
    2. Run this script pointing to those files:
       `python ingest_expertise_definitions.py --expertise_id test_exp_001`
       Or, specify files individually:
       `python ingest_expertise_definitions.py --artifacts_file test_exp_001_data_artifacts.json --model_file test_exp_001_ml_model.json`
    3. Check the console output and `ingestion_framework_activity.log` for details.
    """
    parser = argparse.ArgumentParser(
        description="Ingest expertise definitions (JSON files) into the Data Mesh Ontology Framework.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument('--artifacts_file', type=str, help="Path to the JSON file containing DataArtifact definitions.")
    parser.add_argument('--model_file', type=str, help="Path to the JSON file containing an MLModel definition.")
    parser.add_argument('--fl_setup_file', type=str, help="Path to the JSON file containing a Federated Learning setup definition.")
    parser.add_argument('--expertise_id', type=str,
                        help="Optional expertise ID. If provided, attempts to load conventionally named files\n"
                             "(e.g., '{expertise_id}_data_artifacts.json') if specific paths are not set.")

    args = parser.parse_args()

    artifacts_fpath = args.artifacts_file
    model_fpath = args.model_file
    fl_setup_fpath = args.fl_setup_file

    if args.expertise_id:
        logging.info(f"Expertise ID '{args.expertise_id}' provided. Constructing default filenames if specific paths are not set.")
        artifacts_fpath = artifacts_fpath or f"{args.expertise_id}_data_artifacts.json"
        model_fpath = model_fpath or f"{args.expertise_id}_ml_model.json"
        fl_setup_fpath = fl_setup_fpath or f"{args.expertise_id}_federated_setup.json"

    # argparse automatically handles the case where no arguments are given by showing help.
    # This script will only proceed if at least one file path is determined.
    if not (artifacts_fpath or model_fpath or fl_setup_fpath):
        # This specific check might be redundant if argparse requires at least one of our defined args,
        # or if we only proceed if at least one path is valid.
        # However, if all paths resolved to None (e.g. only --expertise_id given but it was empty), this is a fallback.
        logging.info("No input files were specified or could be derived. To run, provide file paths or an expertise_id.")
        if not any(vars(args).values()): # Check if any arguments were actually passed
             parser.print_help()
        return

    initialize_framework_components()

    # Process files if their paths are valid and they exist
    # DataArtifacts
    if artifacts_fpath and os.path.exists(artifacts_fpath):
        logging.info(f"--- Starting DataArtifact Ingestion from {artifacts_fpath} ---")
        ingest_data_artifacts(artifacts_fpath)
    elif args.artifacts_file : # File was explicitly specified but not found
        logging.warning(f"Specified DataArtifacts file not found: {args.artifacts_file} (Skipping)")
    elif artifacts_fpath : # File was derived from expertise_id but not found
        logging.info(f"DataArtifacts file derived from expertise_id not found: {artifacts_fpath} (Skipping)")


    # MLModel
    if model_fpath and os.path.exists(model_fpath):
        logging.info(f"--- Starting MLModel Ingestion from {model_fpath} ---")
        ingest_ml_model(model_fpath)
    elif args.model_file:
        logging.warning(f"Specified MLModel file not found: {args.model_file} (Skipping)")
    elif model_fpath:
        logging.info(f"MLModel file derived from expertise_id not found: {model_fpath} (Skipping)")

    # Federated Learning Setup
    if fl_setup_fpath and os.path.exists(fl_setup_fpath):
        logging.info(f"--- Starting Federated Learning Setup Ingestion from {fl_setup_fpath} ---")
        ingest_federated_setup(fl_setup_fpath)
    elif args.fl_setup_file:
        logging.warning(f"Specified Federated Learning setup file not found: {args.fl_setup_file} (Skipping)")
    elif fl_setup_fpath:
        logging.info(f"Federated Learning setup file derived from expertise_id not found: {fl_setup_fpath} (Skipping)")

    logging.info("Ingestion process finished.")


if __name__ == '__main__':
    # This is the entry point when the script is run directly from the command line.
    main()
